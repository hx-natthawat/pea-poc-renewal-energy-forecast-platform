# Default values for pea-re-forecast
# This is a YAML-formatted file.

global:
  namespace: pea-forecast
  imageRegistry: ""
  imagePullSecrets: []

# Backend API Configuration
backend:
  enabled: true
  replicaCount: 2
  image:
    repository: pea-forecast/backend
    tag: latest
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 8000
  resources:
    requests:
      memory: "256Mi"
      cpu: "200m"
    limits:
      memory: "1Gi"
      cpu: "1000m"
  env:
    APP_ENV: development
    MODEL_PATH: /app/models
  probes:
    liveness:
      path: /api/v1/health
      initialDelaySeconds: 30
      periodSeconds: 10
    readiness:
      path: /api/v1/health
      initialDelaySeconds: 10
      periodSeconds: 5
  autoscaling:
    enabled: false
    minReplicas: 2
    maxReplicas: 10
    targetCPUUtilization: 70
    targetMemoryUtilization: 80

# Frontend Dashboard Configuration
frontend:
  enabled: true
  replicaCount: 2
  image:
    repository: pea-forecast/frontend
    tag: latest
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 3000
  resources:
    requests:
      memory: "128Mi"
      cpu: "100m"
    limits:
      memory: "512Mi"
      cpu: "500m"
  env:
    NEXT_PUBLIC_API_URL: http://backend:8000
  autoscaling:
    enabled: false
    minReplicas: 2
    maxReplicas: 5
    targetCPUUtilization: 70

# TimescaleDB Configuration
timescaledb:
  enabled: true
  image:
    repository: timescale/timescaledb
    tag: latest-pg16
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 5432
  persistence:
    enabled: true
    size: 10Gi
    storageClass: ""
  resources:
    requests:
      memory: "512Mi"
      cpu: "250m"
    limits:
      memory: "2Gi"
      cpu: "1000m"
  auth:
    database: pea_forecast
    username: postgres
    password: postgres
    existingSecret: ""

# Redis Configuration
redis:
  enabled: true
  image:
    repository: redis
    tag: "7-alpine"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 6379
  persistence:
    enabled: false
    size: 1Gi
  resources:
    requests:
      memory: "64Mi"
      cpu: "50m"
    limits:
      memory: "256Mi"
      cpu: "200m"
  config:
    maxmemory: "128mb"
    maxmemoryPolicy: "allkeys-lru"

# Ingress Configuration
# Single endpoint with path-based routing to different services
ingress:
  enabled: true
  className: nginx
  annotations:
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/rewrite-target: /$1
  hosts:
    - host: pea-forecast.local
      paths:
        # API Backend: pea-forecast.local/api/* → backend:8000
        - path: /api/(.*)
          pathType: ImplementationSpecific
          backend: backend
        # ML Service: pea-forecast.local/ml/* → ml:8001
        - path: /ml/(.*)
          pathType: ImplementationSpecific
          backend: mlService
        # Frontend: pea-forecast.local/* → frontend:3000
        - path: /(.*)
          pathType: ImplementationSpecific
          backend: frontend
  tls: []

# CORS Configuration
cors:
  origins:
    - "http://localhost:3000"
    - "http://frontend:3000"

# ML Service Configuration (TOR 7.1.1: AI/ML Server)
mlService:
  enabled: true
  replicaCount: 1
  image:
    repository: pea-forecast/ml
    tag: latest
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 8001
  modelPath: /app/models
  mlflowUri: ""
  resources:
    requests:
      memory: "2Gi"
      cpu: "1000m"
    limits:
      memory: "8Gi"
      cpu: "4000m"
  env:
    PYTHONPATH: /app
    LOG_LEVEL: INFO
  probes:
    liveness:
      path: /health
      initialDelaySeconds: 60
      periodSeconds: 30
      timeoutSeconds: 10
      failureThreshold: 3
    readiness:
      path: /health
      initialDelaySeconds: 30
      periodSeconds: 10
      timeoutSeconds: 5
      successThreshold: 1
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 5
    targetCPUUtilization: 70
    targetMemoryUtilization: 80
  persistence:
    enabled: false
    size: 10Gi
    storageClass: ""
    modelStorage:
      enabled: false
      size: 5Gi
      storageClass: ""
  nodeSelector: {}
  tolerations: []
  affinity: {}

# Monitoring
monitoring:
  enabled: false
  prometheus:
    scrape: true
    port: 8000
    path: /metrics

# Network Policies (Cilium CNI - TOR 7.1.3)
# Enable in production for zero-trust networking
networkPolicy:
  enabled: false  # Enable in production

# HashiCorp Vault Configuration (TOR Table 2: Key Management)
vault:
  enabled: false  # Enable in production for secrets management
  address: "http://vault.vault.svc.cluster.local:8200"
  role: "pea-forecast-backend"
  mountPoint: "pea-forecast"
  # Agent injector annotations (added to backend deployment when enabled)
  agent:
    enabled: false
    inject: true
    image: "hashicorp/vault:1.21.1"
    secrets:
      - path: "pea-forecast/data/database"
        template: |
          {{- with secret "pea-forecast/data/database" -}}
          export DATABASE_URL="{{ .Data.data.DATABASE_URL }}"
          export DB_USER="{{ .Data.data.DB_USER }}"
          export DB_PASSWORD="{{ .Data.data.DB_PASSWORD }}"
          {{- end }}
      - path: "pea-forecast/data/redis"
        template: |
          {{- with secret "pea-forecast/data/redis" -}}
          export REDIS_URL="{{ .Data.data.REDIS_URL }}"
          {{- end }}
      - path: "pea-forecast/data/app"
        template: |
          {{- with secret "pea-forecast/data/app" -}}
          export APP_SECRET_KEY="{{ .Data.data.APP_SECRET_KEY }}"
          {{- end }}
  # SDK-based secrets loading (alternative to agent injector)
  sdk:
    enabled: true  # Use Python hvac library
    env:
      VAULT_ENABLED: "true"
      VAULT_ADDR: "http://vault.vault.svc.cluster.local:8200"
      VAULT_ROLE: "pea-forecast-backend"
      VAULT_MOUNT_POINT: "pea-forecast"
